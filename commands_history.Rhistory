list(cv_inner$test_set(i)))
# auto tuner
at_nonfilter = auto_tuner(
tuner = tnr("grid_search", resolution = 20, batch_size = 2),
learner = graph_nonpca,
resampling = custom_,
measure = msr("regr.mse"),
search_space = search_space_nonpca
)
# auto tuner
at_filter = auto_tuner(
tuner = tnr("grid_search", resolution = 20, batch_size = 2),
learner = graph_pca_lrn,
resampling = custom_,
measure = msr("regr.mse"),
search_space = search_space
)
# outer resampling
customo_ = rsmp("custom")
customo_$id = paste0("custom_", cv_inner$iters, "_", i)
task_outer = task_$clone()
task_outer$id = "task_outer"
customo_$instantiate(task_outer,
list(cv_outer$train_set(i)),
list(cv_outer$test_set(i)))
# nested CV for one round
design = benchmark_grid(
tasks = task_,
learners = list(at_filter, at_nonfilter),
resamplings = customo_
)
})
designs_cv = do.call(rbind, designs_cv_l)
# batchmark(designs)
})
designs = do.call(rbind, designs_l)
# exp dir
if (interactive()) {
dirname_ = "experiments_test"
if (dir.exists(dirname_)) system(paste0("rm -r ", dirname_))
} else {
dirname_ = "experiments"
}
# create registry
print("Create registry")
packages = c("data.table", "gausscov", "paradox", "mlr3", "mlr3pipelines",
"mlr3tuning", "mlr3misc", "future", "future.apply",
"mlr3extralearners")
reg = makeExperimentRegistry(file.dir = dirname_, seed = 1, packages = packages)
# populate registry with problems and algorithms to form the jobs
print("Batchmark")
batchmark(designs, reg = reg, store_models = TRUE)
# save registry
print("Save registry")
saveRegistry(reg = reg)
# If interactive train models, else create file
if (interactive()) {
test = batchtools::testJob(1, reg = reg)
} else {
# create sh file
sh_file = sprintf("
#!/bin/bash
#PBS -N H2
#PBS -l ncpus=4
#PBS -l mem=16GB
#PBS -J 1-%d
#PBS -o experiments/logs
#PBS -j oe
cd ${PBS_O_WORKDIR}
apptainer run image.sif run_job.R 0
", nrow(designs))
sh_file_name = "padobran.sh"
file.create(sh_file_name)
writeLines(sh_file, sh_file_name)
}
# test MLP learner
mlp_graph = po("torch_ingress_num") %>>%
po("nn_linear", out_features = 20) %>>%
po("nn_relu") %>>%
po("nn_head") %>>%
po("torch_loss", loss = t_loss("mse")) %>>%
po("torch_optimizer", optimizer = t_opt("adam", lr = 0.1)) %>>%
po("torch_callbacks", callbacks = t_clbk("history")) %>>%
po("torch_model_regr", batch_size = 16, epochs = 50, device = "cpu")
# cretate learners graph node
learners_l = list(
ranger  = lrn("regr.ranger", id = "ranger"),
xgboost = lrn("regr.xgboost", id = "xgboost"),
bart    = lrn("regr.bart", id = "bart"),
nnet    = lrn("regr.nnet", id = "nnet", MaxNWts = 50000),
mlp     = mlp_graph,
tabnet  = lrn("regr_tabnet", id = "tabnet")
)
# create regression average of all learners
choices = c("ranger", "xgboost", "bart", "nnet", "mlp", "tabnet")
learners = po("branch", choices) %>>%
gunion(learners_l) %>>%
po("unbranch")
# non filter ghraph
graph_nonfilter = po("dropnacol", id = "dropnacol", cutoff = 0.05) %>>%
po("dropna", id = "dropna") %>>%
po("removeconstants", id = "removeconstants_1", ratio = 0)  %>>%
po("winsorizesimple", id = "winsorizesimple", probs_low = 0.01, probs_high = 0.99, na_rm = TRUE) %>>%
po("removeconstants", id = "removeconstants_2", ratio = 0)  %>>%
po("dropcorr", id = "dropcorr", cutoff = 0.99) %>>%
po("uniformization") %>>%
po("dropna", id = "dropna_v2") %>>%
learners
plot(graph_nonfilter)
graph_nonfilter_lrn = as_learner(graph_nonfilter)
# pca ghraph
graph_filter = po("dropnacol", id = "dropnacol", cutoff = 0.05) %>>%
po("dropna", id = "dropna") %>>%
po("removeconstants", id = "removeconstants_1", ratio = 0)  %>>%
po("winsorizesimple", id = "winsorizesimple", probs_low = 0.01, probs_high = 0.99, na_rm = TRUE) %>>%
po("removeconstants", id = "removeconstants_2", ratio = 0)  %>>%
po("dropcorr", id = "dropcorr", cutoff = 0.99) %>>%
po("uniformization") %>>%
po("dropna", id = "dropna_v2") %>>%
# po("pca") %>>%
po("filter_rows") %>>%
learners
plot(graph_filter)
graph_filter_lrn = as_learner(graph_filter)
# threads
print("Set threads")
threads = 2
set_threads(graph_filter_lrn, n = threads)
set_threads(graph_nonfilter_lrn, n = threads)
# non filter params
search_space_nonpca = ps(
branch.selection = p_fct(choices)
)
# pca params
as.data.table(graph_pca_lrn$param_set)[, .(id, class, lower, upper)]
as.data.table(graph_pca_lrn$param_set)[1:100, .(id, class, lower, upper)]
search_space = ps(
filterrows_fct = p_fct(levels = c("event_vol_100_1",
"event_vol_100_2")),
# learner branch
branch.selection = p_fct(choices),
.extra_trafo = function(x, param_set) {
if (x$filterrows_fct == "event_vol_100_1") {
x$filterrows.filter_formula = "~ event_vol_100_1 == 1"
} else if ((x$filterrows_fct == "event_vol_100_2")) {
x$filterrows.filter_formula = "~ event_vol_100_2 == 1"
}
return(x)
}
)
# eventVol1001 eventVol1002 eventVol1003 eventVol4501 eventVol4502 eventVol4503
# create designs
print("Create designs")
designs_l = lapply(seq_along(custom_cvs)[1], function(j) {
# debug
# j = 1
task_ = tasks[[j]]$clone()
cv_ = custom_cvs[[j]]
# get cv inner object
cv_inner = cv_$inner
cv_outer = cv_$outer
cat("Number of iterations fo cv inner is ", cv_inner$iters, "\n")
# debug
if (interactive()) {
to_ = 2
} else {
to_ = cv_inner$iters
}
designs_cv_l = lapply(1:to_, function(i) { # 1:cv_inner$iters
# debug
# i = 1
# choose task_
print(cv_inner$id)
# with new mlr3 version I have to clone
task_inner = task_$clone()
task_inner$id = "task_inner"
task_inner$filter(c(cv_inner$train_set(i), cv_inner$test_set(i)))
# inner resampling
custom_ = rsmp("custom")
custom_$id = paste0("custom_", cv_inner$iters, "_", i)
custom_$instantiate(task_inner,
list(cv_inner$train_set(i)),
list(cv_inner$test_set(i)))
# auto tuner
at_nonfilter = auto_tuner(
tuner = tnr("grid_search", resolution = 20, batch_size = 2),
learner = graph_nonfilter,
resampling = custom_,
measure = msr("regr.mse"),
search_space = search_space_nonpca
)
# auto tuner
at_filter = auto_tuner(
tuner = tnr("grid_search", resolution = 20, batch_size = 2),
learner = graph_filter_lrn,
resampling = custom_,
measure = msr("regr.mse"),
search_space = search_space
)
# outer resampling
customo_ = rsmp("custom")
customo_$id = paste0("custom_", cv_inner$iters, "_", i)
task_outer = task_$clone()
task_outer$id = "task_outer"
customo_$instantiate(task_outer,
list(cv_outer$train_set(i)),
list(cv_outer$test_set(i)))
# nested CV for one round
design = benchmark_grid(
tasks = task_,
learners = list(at_filter, at_nonfilter),
resamplings = customo_
)
})
designs_cv = do.call(rbind, designs_cv_l)
# batchmark(designs)
})
designs = do.call(rbind, designs_l)
# exp dir
if (interactive()) {
dirname_ = "experiments_test"
if (dir.exists(dirname_)) system(paste0("rm -r ", dirname_))
} else {
dirname_ = "experiments"
}
# create registry
print("Create registry")
packages = c("data.table", "gausscov", "paradox", "mlr3", "mlr3pipelines",
"mlr3tuning", "mlr3misc", "future", "future.apply",
"mlr3extralearners")
reg = makeExperimentRegistry(file.dir = dirname_, seed = 1, packages = packages)
# populate registry with problems and algorithms to form the jobs
print("Batchmark")
batchmark(designs, reg = reg, store_models = TRUE)
# save registry
print("Save registry")
saveRegistry(reg = reg)
# If interactive train models, else create file
if (interactive()) {
test = batchtools::testJob(1, reg = reg)
} else {
# create sh file
sh_file = sprintf("
#!/bin/bash
#PBS -N H2
#PBS -l ncpus=4
#PBS -l mem=16GB
#PBS -J 1-%d
#PBS -o experiments/logs
#PBS -j oe
cd ${PBS_O_WORKDIR}
apptainer run image.sif run_job.R 0
", nrow(designs))
sh_file_name = "padobran.sh"
file.create(sh_file_name)
writeLines(sh_file, sh_file_name)
}
as.data.table(graph_pca_lrn$param_set)[1:100, .(id, class, lower, upper)]
as.character(1:6)
search_space = ps(
filterrows.filter_formula = p_fct(levels = as.character(1:6)),
# learner branch
branch.selection = p_fct(choices),
.extra_trafo = function(x, param_set) {
if (x$filterrows.filter_formula == "1") {
x$filterrows.filter_formula = "~ eventVol1001 == 1"
} else if ((x$filterrows.filter_formula == "2")) {
x$filterrows.filter_formula = "~ eventVol1002 == 1"
} else if ((x$filterrows.filter_formula == "3")) {
x$filterrows.filter_formula = "~ eventVol1003 == 1"
} else if ((x$filterrows.filter_formula == "4")) {
x$filterrows.filter_formula = "~ eventVol4501 == 1"
} else if ((x$filterrows.filter_formula == "5")) {
x$filterrows.filter_formula = "~ eventVol4502 == 1"
} else if ((x$filterrows.filter_formula == "6")) {
x$filterrows.filter_formula = "~ eventVol4503 == 1"
}
return(x)
}
)
# create designs
print("Create designs")
seq_along(custom_cvs)
if (interactive()) {
from_ = 1
} else {
from_ = seq_along(custom_cvs)
}
from_
designs_l = lapply(from_, function(j) {
# debug
# j = 1
task_ = tasks[[j]]$clone()
cv_ = custom_cvs[[j]]
# get cv inner object
cv_inner = cv_$inner
cv_outer = cv_$outer
cat("Number of iterations fo cv inner is ", cv_inner$iters, "\n")
# debug
if (interactive()) {
to_ = 2
} else {
to_ = cv_inner$iters
}
designs_cv_l = lapply(1:to_, function(i) { # 1:cv_inner$iters
# debug
# i = 1
# choose task_
print(cv_inner$id)
# with new mlr3 version I have to clone
task_inner = task_$clone()
task_inner$id = "task_inner"
task_inner$filter(c(cv_inner$train_set(i), cv_inner$test_set(i)))
# inner resampling
custom_ = rsmp("custom")
custom_$id = paste0("custom_", cv_inner$iters, "_", i)
custom_$instantiate(task_inner,
list(cv_inner$train_set(i)),
list(cv_inner$test_set(i)))
# auto tuner
at_nonfilter = auto_tuner(
tuner = tnr("grid_search", resolution = 20, batch_size = 2),
learner = graph_nonfilter,
resampling = custom_,
measure = msr("regr.mse"),
search_space = search_space_nonpca
)
# auto tuner
at_filter = auto_tuner(
tuner = tnr("grid_search", resolution = 20, batch_size = 2),
learner = graph_filter_lrn,
resampling = custom_,
measure = msr("regr.mse"),
search_space = search_space
)
# outer resampling
customo_ = rsmp("custom")
customo_$id = paste0("custom_", cv_inner$iters, "_", i)
task_outer = task_$clone()
task_outer$id = "task_outer"
customo_$instantiate(task_outer,
list(cv_outer$train_set(i)),
list(cv_outer$test_set(i)))
# nested CV for one round
design = benchmark_grid(
tasks = task_,
learners = list(at_filter, at_nonfilter),
resamplings = customo_
)
})
designs_cv = do.call(rbind, designs_cv_l)
# batchmark(designs)
})
designs = do.call(rbind, designs_l)
designs
# exp dir
if (interactive()) {
dirname_ = "experiments_test"
if (dir.exists(dirname_)) system(paste0("rm -r ", dirname_))
} else {
dirname_ = "experiments"
}
# create registry
print("Create registry")
packages = c("data.table", "gausscov", "paradox", "mlr3", "mlr3pipelines",
"mlr3tuning", "mlr3misc", "future", "future.apply",
"mlr3extralearners")
reg = makeExperimentRegistry(file.dir = dirname_, seed = 1, packages = packages)
# populate registry with problems and algorithms to form the jobs
print("Batchmark")
batchmark(designs, reg = reg, store_models = TRUE)
# save registry
print("Save registry")
saveRegistry(reg = reg)
test = batchtools::testJob(1, reg = reg)
search_space = ps(
filterrows.filter_formula = p_fct(levels = as.character(1:6)),
# learner branch
branch.selection = p_fct(choices),
.extra_trafo = function(x, param_set) {
if (x$filterrows.filter_formula == "1") {
x$filterrows.filter_formula = as.formula("~ eventVol1001 == 1")
} else if ((x$filterrows.filter_formula == "2")) {
x$filterrows.filter_formula = as.formula("~ eventVol1002 == 1")
} else if ((x$filterrows.filter_formula == "3")) {
x$filterrows.filter_formula = as.formula("~ eventVol1003 == 1")
} else if ((x$filterrows.filter_formula == "4")) {
x$filterrows.filter_formula = as.formula("~ eventVol4501 == 1")
} else if ((x$filterrows.filter_formula == "5")) {
x$filterrows.filter_formula = as.formula("~ eventVol4502 == 1")
} else if ((x$filterrows.filter_formula == "6")) {
x$filterrows.filter_formula = as.formula("~ eventVol4503 == 1")
}
return(x)
}
)
# create designs
print("Create designs")
if (interactive()) {
from_ = 1
} else {
from_ = seq_along(custom_cvs)
}
designs_l = lapply(from_, function(j) {
# debug
# j = 1
task_ = tasks[[j]]$clone()
cv_ = custom_cvs[[j]]
# get cv inner object
cv_inner = cv_$inner
cv_outer = cv_$outer
cat("Number of iterations fo cv inner is ", cv_inner$iters, "\n")
# debug
if (interactive()) {
to_ = 2
} else {
to_ = cv_inner$iters
}
designs_cv_l = lapply(1:to_, function(i) { # 1:cv_inner$iters
# debug
# i = 1
# choose task_
print(cv_inner$id)
# with new mlr3 version I have to clone
task_inner = task_$clone()
task_inner$id = "task_inner"
task_inner$filter(c(cv_inner$train_set(i), cv_inner$test_set(i)))
# inner resampling
custom_ = rsmp("custom")
custom_$id = paste0("custom_", cv_inner$iters, "_", i)
custom_$instantiate(task_inner,
list(cv_inner$train_set(i)),
list(cv_inner$test_set(i)))
# auto tuner
at_nonfilter = auto_tuner(
tuner = tnr("grid_search", resolution = 20, batch_size = 2),
learner = graph_nonfilter,
resampling = custom_,
measure = msr("regr.mse"),
search_space = search_space_nonpca
)
# auto tuner
at_filter = auto_tuner(
tuner = tnr("grid_search", resolution = 20, batch_size = 2),
learner = graph_filter_lrn,
resampling = custom_,
measure = msr("regr.mse"),
search_space = search_space
)
# outer resampling
customo_ = rsmp("custom")
customo_$id = paste0("custom_", cv_inner$iters, "_", i)
task_outer = task_$clone()
task_outer$id = "task_outer"
customo_$instantiate(task_outer,
list(cv_outer$train_set(i)),
list(cv_outer$test_set(i)))
# nested CV for one round
design = benchmark_grid(
tasks = task_,
learners = list(at_filter, at_nonfilter),
resamplings = customo_
)
})
designs_cv = do.call(rbind, designs_cv_l)
# batchmark(designs)
})
designs = do.call(rbind, designs_l)
# exp dir
if (interactive()) {
dirname_ = "experiments_test"
if (dir.exists(dirname_)) system(paste0("rm -r ", dirname_))
} else {
dirname_ = "experiments"
}
# create registry
print("Create registry")
packages = c("data.table", "gausscov", "paradox", "mlr3", "mlr3pipelines",
"mlr3tuning", "mlr3misc", "future", "future.apply",
"mlr3extralearners")
reg = makeExperimentRegistry(file.dir = dirname_, seed = 1, packages = packages)
# populate registry with problems and algorithms to form the jobs
print("Batchmark")
batchmark(designs, reg = reg, store_models = TRUE)
# save registry
print("Save registry")
saveRegistry(reg = reg)
# If interactive train models, else create file
if (interactive()) {
test = batchtools::testJob(1, reg = reg)
test2 = batchtools::testJob(2, reg = reg)
} else {
# create sh file
sh_file = sprintf("
#!/bin/bash
#PBS -N H2
#PBS -l ncpus=4
#PBS -l mem=16GB
#PBS -J 1-%d
#PBS -o experiments/logs
#PBS -j oe
cd ${PBS_O_WORKDIR}
apptainer run image.sif run_job.R 0
", nrow(designs))
sh_file_name = "padobran.sh"
file.create(sh_file_name)
writeLines(sh_file, sh_file_name)
}
colnames(task$data())
tasks[[1]]$feature_names
tasks[[1]]$feature_names[grep("event", tasks[[1]]$feature_names)]
savehistory("commands_history.Rhistory")
